---
title: "Sentiment-Analysis"
author: "Deepanshu Goyal"
date: "December 18, 2019"
output: html_document
---

```{r Install required package & custom functions, message=FALSE, warning=FALSE}
rm(list=ls()) 
source('https://raw.githubusercontent.com/deepanshu-goyal/Text-Analytics/master/Common_Functions.R')

if (!require(qdap)) {install.packages("qdap")}
if(!require(textdata)) {install.packages("textdata")}
if(!require(ggraph)) {install.packages("ggraph")}
if(!require(ldatuning)) {install.packages("ldatuning")}
if (!require(udpipe)){install.packages("udpipe")}

library(qdap)
library(sentimentr)
library(tidytext)
library(ggraph)
library(igraph)
library(topicmodels)
library(ldatuning)
library(udpipe)
```

## Step 1: Read data from csv file and seperate reviews for Seltos, Compass & Hector

```{r read csv files, warning=FALSE}
setwd(getwd())
data = read.csv('https://raw.githubusercontent.com/deepanshu-goyal/Text-Analytics/master/FinalReview.csv', header = TRUE,sep = ',')

seltos = data %>% filter(Brand=="Kia Seltos")
compass = data %>% filter(Brand =="Jeep Compass")
hector = data %>% filter(Brand== "MG Hector")

```

## Random sample 400 reviews for each car type 

Random sample 400 reviews for each car, this will help in comparative analysis.We have used sample without replacement to get one review only once. 

```{r}
seltos_sample = sample_n(seltos, 400, replace = FALSE)
compass_sample = sample_n(compass, 400, replace = FALSE)
hector_sample = sample_n(hector, 400, replace = FALSE)


final_df = bind_rows(seltos_sample,compass_sample,hector_sample)


review_df = data_frame(brand = tolower(as.character(final_df$Brand)),review = tolower(as.character(final_df$Review)))
review_dtm = create_dtm(final_df)

review_sent = get_sentences(review_df)
review_sent$topic = NA


```



## Step 2: Find out key Features/Topics in a corpus
Option1: Using word frequency, bigrams & COG graphs
Option2: Using Nouns or Noun Phrases
Option3: using Topic modeling techniques such as LDA
Option4: using clustering technique - k means  

Option1: Use bigrams & graphs (COG, igraph)
```{r Cooccurange graphs for car reviews}

#COG for all the reviews
review_bigram = create_bigram(final_df)

create.graph(review_bigram,10)

distill.cog(review_dtm, 'COG of Car Reviews',12)

```

Option2: Feature extraction using Nouns or Nouns Phrases

```{r Feature extraction using Noun or Noun Phrases}

#ud_model_english <- udpipe_download_model(language = "english")

english_model = udpipe_load_model("./english-ewt-ud-2.4-190531.udpipe")

data_nlp = udpipe_annotate(english_model,x=review_df$review)

data_nlp = as.data.frame(data_nlp)
data_nlp$tag = as_phrasemachine(data_nlp$upos, type = 'upos')
head(data_nlp)

#noun_phrase = keywords_phrases(x = data_nlp$tag,term = tolower(data_nlp$token),
#                                   pattern = "(A|N)*N(P+D*(A|N)*N)*", 
#                                   is_regex = TRUE, detailed = FALSE)

#noun_phrase = subset(noun_phrase,ngram>1 & freq>1)
#head(noun_phrase,20)
```

```{r Frequent NOUN in the entire corpus}
data_noun = data_nlp %>% subset(., upos %in% 'NOUN')
top_noun = txt_freq(data_noun$lemma)

values = c('kia','seltos', 'mg','hector','jeep','compass')
top_noun = top_noun %>% filter(!key %in% values)

head(top_noun,20)
```
```{r frequent occurance of two words in the entire corpus}
data_cooc = cooccurrence(x = data_nlp$lemma, 
                           relevant =  data_nlp$upos %in% c('NOUN'))

data_cooc = data_cooc %>% filter(!term1 %in% values) %>% filter(!term2 %in% values)
head(data_cooc,20)
```

```{r frequent occurance of two words in each document}
data_co = cooccurrence(x = subset(data_nlp, upos %in% c('NOUN')),
                        term = 'lemma',
                        group = c("doc_id"))
data_co = data_co %>% filter(!term1 %in% values) %>% filter(!term2 %in% values)

head(data_co,20)
```



option3: Find topics using topic modeling - LDA


```{r find number of optimal topics in LDA}

result = ldatuning::FindTopicsNumber(
  review_dtm,
  topics = seq(from = 2, to = 20, by = 1),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 77),
  mc.cores = 2L,
  verbose = TRUE
)

ldatuning::FindTopicsNumber_plot(result)
```



```{r Find topics using LDA - 12 Topics}
#find topics from consolidated data (Seltos, Jeep, Hector)
find_topics(review_dtm,12)
```
## Step 3: Choose Features/Topics

```{r Keywords}
keywords = c('ground clearance','price range','design','petrol engine','diesel engine','sound','clutch','service',
             'interior','driving experience','sunroof','mileage','build quality','safety','boot space', 'gearbox',
             'seats','ride quality','air purifier','power')


for (feature in keywords){
      review_sent$topic = ifelse(grepl(feature,review_sent$review),feature,review_sent$topic)
    }
    
review_filter = review_sent[!is.na(review_sent$topic),]

review_bow = review_filter %>% group_by(brand) %>% mutate(doc_id=row_number()) %>% ungroup() %>% unnest_tokens(word,review)


#Filtered reviews for each car type
seltos_filter = review_filter %>% filter(brand=='kia seltos') %>% mutate(element_id=row_number()) %>%
                select(element_id, brand,review,topic)
seltos_review = tolower(as.character(seltos_filter$review))

compass_filter = review_filter %>% filter(brand=='jeep compass') %>% mutate(element_id=row_number()) %>%
                select(element_id, brand,review,topic)
compass_review = tolower(as.character(compass_filter$review))

hector_filter = review_filter %>% filter(brand=='mg hector') %>% mutate(element_id=row_number()) %>%
                select(element_id, brand,review,topic)
hector_review = tolower(as.character(hector_filter$review))


```


## Step 4: Score each document usig standard dictionary, QDAP(Princeton dictionary) & SentimentR (Lexicon & Valence shifter)

Type 1: Using Dictionary ( bing, afinn & nrc) 

```{r get lexicon}
afinn = get_sentiments("afinn")
bing =  get_sentiments("bing")
nrc = get_sentiments("nrc")
```

## Scoring using BING dictionary i.e. difference of postive & negative words in each document. Find out the average for the entire corpus

```{r Sentiment analsysis using bing dictionary}
#Select document based on feature
bing_score = review_bow %>% inner_join(bing) %>% count(brand,element_id,sentiment) %>% spread(sentiment,n,fill = 0) %>%                group_by(brand,element_id) %>% summarise(sentiment=positive-negative)

# Overall keyword based score
overall_score1 = inner_join(bing_score,review_filter,by=c("brand","element_id")) %>% group_by(brand,topic) %>% summarise(cov_score = mean(sentiment)/sd(sentiment)) %>% spread(topic,cov_score, fill = 0)
overall_score1

#Overall Score
score_bing = bing_score %>% group_by(brand) %>% summarise(mean_Score = mean(sentiment), sd_score = sd(sentiment),cov_score = mean_Score/sd_score)
score_bing

ggplot(bing_score,aes(element_id,sentiment, fill=brand))+
  geom_col()+
  facet_wrap(~brand,ncol=1,scales = "free_x")

```

## Scoring using AFINN dictionary.Find out the average for the entire corpus
```{r Sentiment analsysis using afinn dictionary}

affin_score = review_bow %>% inner_join(afinn) %>% group_by(brand,element_id) %>% summarise(sentiment = sum(value))


# Overall keyword based score
overall_score2 = inner_join(affin_score,review_filter,by=c("brand","element_id")) %>% group_by(brand,topic) %>% summarise(cov_score = mean(sentiment)/sd(sentiment)) %>% spread(topic,cov_score, fill = 0)
overall_score2

#Overall Score
score_affin = affin_score %>% group_by(brand) %>% summarise(mean_Score = mean(sentiment), sd_score = sd(sentiment),cov_score = mean_Score/sd_score)
score_affin

ggplot(affin_score,aes(element_id,sentiment, fill=brand))+
  geom_col()+
  facet_wrap(~brand,ncol=1,scales = "free_x")


```


## Scoring using NRC dictionary.Find out the average for the entire corpus
```{r}
#Select document based on feature

nrc_score = review_bow %>% inner_join(nrc) %>% count(brand,element_id,sentiment) %>% spread(sentiment, n, fill=0) %>% group_by(brand, element_id) %>% summarise(sentiment = positive-negative)

# Overall keyword based score
overall_score3 = inner_join(nrc_score,review_filter,by=c("brand","element_id")) %>% group_by(brand,topic) %>% summarise(cov_score = mean(sentiment)/sd(sentiment)) %>% spread(topic,cov_score, fill = 0)
overall_score3

#Overall Score
score_nrc = nrc_score %>% group_by(brand) %>% summarise(mean_Score = mean(sentiment), sd_score = sd(sentiment),cov_score = mean_Score/sd_score)
score_nrc

ggplot(nrc_score,aes(element_id,sentiment,fill=brand))+
  geom_col()+
  facet_wrap(~brand,ncol=1,scales = "free_x")
```

## Type 2: Polarity Score using qdap

```{r Sentiment Score using Qdap-Polarity Score}


#Calculate polarity score for Kia Seltos

seltos_polarity = qdap::polarity(seltos_review)

seltos_feature_score = seltos_polarity$all %>% mutate(element_id = row_number()) %>% 
                select(element_id,polarity, text.var) %>% inner_join(seltos_filter,by=('element_id'))%>%
                group_by(brand, topic) %>% summarise(cov_score = mean(polarity)/sd(polarity)) %>%
                spread(topic,cov_score,fill = 0)

#Calculate polarity score for Jeep Compass

compass_polarity = qdap::polarity(compass_review)

compass_feature_score = compass_polarity$all %>% mutate(element_id = row_number()) %>% 
                select(element_id,polarity, text.var) %>% inner_join(compass_filter,by=('element_id'))%>%
                group_by(brand, topic) %>% summarise(cov_score = mean(polarity)/sd(polarity)) %>%
                spread(topic,cov_score,fill = 0)


#Calculate polarity score for MG Hector

hector_polarity = qdap::polarity(hector_review)

hector_feature_score = hector_polarity$all %>% mutate(element_id = row_number()) %>% 
                select(element_id,polarity, text.var) %>% inner_join(hector_filter,by=('element_id')) %>%
                group_by(brand, topic) %>% summarise(cov_score = mean(polarity)/sd(polarity)) %>%
                spread(topic,cov_score,fill = 0)


compass_qdap = data.frame(brand="Jeep Compass", mean_score = compass_polarity$group$ave.polarity, sd_score = compass_polarity$group$sd.polarity, cov_score = compass_polarity$group$stan.mean.polarity)

seltos_qdap = data.frame(brand="Kia Seltos", mean_score = seltos_polarity$group$ave.polarity, sd_score = seltos_polarity$group$sd.polarity, cov_score = seltos_polarity$group$stan.mean.polarity)

hector_qdap = data.frame(brand="MG Hector", mean_score = hector_polarity$group$ave.polarity, sd_score = hector_polarity$group$sd.polarity, cov_score = hector_polarity$group$stan.mean.polarity)


#feature-wise score
overall_score4 = bind_rows(compass_feature_score,seltos_feature_score,hector_feature_score)
overall_score4

#Cummulative score
bind_rows(compass_qdap, seltos_qdap, hector_qdap)
```
## Type 3: Polarity Score using sentiment (lexicon:hash_sentiment_jockers_rinker & Valence Shifter:hash_valence_shifters)

```{r}
#Calculate sentiment score for Kia Seltos

seltos_score = sentiment(seltos_review, polarity_dt = lexicon::hash_sentiment_jockers_rinker,
               valence_shifters_dt = lexicon::hash_valence_shifters)

s_score = seltos_score %>% summarise(brand = "Kia Seltos", mean_score = mean(sentiment), sd_score = sd(sentiment), cov_score = mean_score/sd_score)

seltos_feature_score  = inner_join(seltos_filter,seltos_score,by='element_id') %>% group_by(brand,topic) %>% 
                        summarise(cov_score = mean(sentiment)/sd(sentiment)) %>% spread(topic,cov_score, fill = 0)


#Calculate sentiment score for Jeep Compass

compass_score = sentiment(compass_review, polarity_dt = lexicon::hash_sentiment_jockers_rinker,
                valence_shifters_dt = lexicon::hash_valence_shifters)

c_score = compass_score %>% summarise(brand = "Jeep Compass", mean_score = mean(sentiment), sd_score = sd(sentiment), cov_score = mean_score/sd_score)


compass_feature_score = inner_join(compass_filter,compass_score,by='element_id') %>% group_by(brand,topic) %>% 
                        summarise(cov_score = mean(sentiment)/sd(sentiment)) %>% spread(topic,cov_score, fill = 0)


#Calculate sentiment score for MG Hector

hector_score = sentiment(hector_review, polarity_dt = lexicon::hash_sentiment_jockers_rinker,
               valence_shifters_dt = lexicon::hash_valence_shifters)

h_score = hector_score %>% summarise(brand = "MG Hector", mean_score = mean(sentiment), sd_score = sd(sentiment), cov_score = mean_score/sd_score)


hector_feature_score = inner_join(hector_filter,hector_score,by='element_id') %>% group_by(brand,topic) %>% 
                        summarise(cov_score = mean(sentiment)/sd(sentiment)) %>% spread(topic,cov_score, fill = 0)



bind_rows(c_score, s_score, h_score)

overall_score5 = bind_rows(compass_feature_score,seltos_feature_score,hector_feature_score)
overall_score5
```

```{r}
overall_score = bind_rows(overall_score1, overall_score2, overall_score3,overall_score4,overall_score5)
write.csv(overall_score,'overall.csv')

```


